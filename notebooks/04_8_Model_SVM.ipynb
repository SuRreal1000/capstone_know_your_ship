{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, the preparation of the data and the SVM model use are describe and shown.  \n",
    "Therefore the DataFrame from \"Featureengineering\" is loaded, together with the feature importance list for this particular model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data file \"Featureengineering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('../data/Featureselection03.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file \"Feature importance list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list with feature importance\n",
    "data_log = pd.read_csv('../data/Capstone_features_Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of important features (feature importance < 3)\n",
    "list_imp_feat = list(data_log[data_log['ModelImportance'] < 3]['VarName'])\n",
    "len(list_imp_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[list_imp_feat].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nan value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['V.SLPOG.act.PRC'].fillna(0,inplace=True)\n",
    "df_model['ME.SFCI.act.gPkWh'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nan values in the tow features are filled with 0, after investigating the data and coming to the conclusion, that the vessel is in the harbour and the Main Engine not running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional nan values are dropped, because the meaningful filling is not possible or to uncertain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,28))\n",
    "sns.heatmap(df_model.corr(), annot = True, cmap = 'RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix is checked again, to ensure no high correlations between features. The feature correlation has been checked in the \"Featureengineering\" already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target and Feature definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop(['ME.FMS.act.tPh'], axis = 1)\n",
    "y = df_model['ME.FMS.act.tPh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supply mass fuel rate as target is separated from the feature dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = X['passage_type'], test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Train split with random_state = 42 to have comparable dataset for the different models. Due to the size fo the dataset the test size is set rather small with 10%:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the passage type (Atalantic, Europe, South America) dummy features are created, to be able to feed the data to the model only as numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open MLFlow and definition of run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "#mlflow.set_tracking_uri(TRACKING_URI)\n",
    "#mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "#mlflow.start_run(run_name='SVM')\n",
    "#run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upload to MLFlow is enabled, to not upload any model results and because the setup is most probably not done for the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipline with SVM Regressor and parameter definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), svm.SVR(kernel='poly',\n",
    "                                            gamma='scale',\n",
    "                                            C=1.0,\n",
    "                                            epsilon=0.1,\n",
    "                                            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a model the SVM Regressor (SVR) is used, with a minMaxSacler.\n",
    "\n",
    "\n",
    "The pipline is set up, with the  \n",
    "* Kernel: \"ploy\"\n",
    "* gama: \"scale\"\n",
    "* C: 1.0\n",
    "* epsilon: 0.1  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict y on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get residuals for the error analysis of regression models, the train datapoints have to be predicted as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model metric the root mean square error ( RMSE) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE train: ', mean_squared_error(y_train, y_pred_train, squared= False))\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared= False)\n",
    "print('RMSE test: ', mean_squared_error(y_test, y_pred, squared= False))\n",
    "rmse_test = mean_squared_error(y_test, y_pred, squared= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot \"Actuel\" vs. \"Predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(6, 6))\n",
    "plt.axline([1, 1], [2, 2],color='lightgrey')\n",
    "plt.scatter(y_train, y_pred_train, color ='#33424F')\n",
    "plt.scatter(y_test, y_pred, color = '#FF6600')\n",
    "plt.xlabel(\"ME.FMS.act.tPh actual\");\n",
    "plt.ylabel(\"ME.FMS.act.tPh predicted\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFlow paramaeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seting parameters that should be logged on MLFlow\n",
    "params = {\n",
    "       'csv used': 'Featureselection03.csv',\n",
    "       'features drop' : 'Accroding to model importance list',\n",
    "       'NaN handling': 'dropped',\n",
    "       'Shape' : df.shape,\n",
    "       'Scaler' : 'MinMaxScaler',\n",
    "       'kernel' : 'poly',\n",
    "       'gamma' : 'scale',\n",
    "       'C' : 1.0,\n",
    "       'epsilon' : 0.1\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down all parameters, which shall be uploaded to MLFlow. This can be different metrics for different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging params to mlflow\n",
    "#mlflow.log_params(params)\n",
    "\n",
    "#setting tags\n",
    "#mlflow.set_tag(\"running_from_jupyter\", \"True\")\n",
    "\n",
    "#logging metrics\n",
    "#mlflow.log_metric(\"train-\" + \"RMSE\", rmse_train)\n",
    "#mlflow.log_metric(\"test-\" + \"RMSE\", rmse_test)\n",
    "\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the upload to MLFlow is enabled to not accidentely try to upload new model runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summery of SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE values from the first runs with the SVM model where not good compared to the other models. Hence some changes where cÂ´done to the model and because the values did not improve significantly the efforts put into this model where reduced and soon decided to not further use it."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61adff6b165475bab44c4811cc98696ba601c22e85e1c32413c6c001d06d5e3a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
