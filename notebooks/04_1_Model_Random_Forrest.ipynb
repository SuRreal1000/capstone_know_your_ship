{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_1 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes the data preparation and the developement of a random forest model.\n",
    "\n",
    "Due to NDA agreements no data can be displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('../data/Featureselection03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list with feature importance\n",
    "data_log = pd.read_csv('../data/Capstone_features_Features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data frame with important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only important features are used to train the model. In this case we use 17 features beside the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of important features (feature importance < 3)\n",
    "list_imp_feat = list(data_log[data_log['ModelImportance'] < 3]['VarName'])\n",
    "len(list_imp_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe consisting of target and 17 features\n",
    "df_model = df[list_imp_feat].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill and drop NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values for V.SLPOG.act.PRC and ME.SFCI.act.gPkWh contain missing values. The EDA showed that these are mainly caused during harbour times when the main engine was not running. Therefore it makes sense to fill the missing values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['V.SLPOG.act.PRC'].fillna(0,inplace=True)\n",
    "df_model['ME.SFCI.act.gPkWh'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining rows with missing values are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project the focus is on optimising the fuel consumption. Therefore the supply mass rate is used as target. Target values greater 8 t/h are defined as outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outlier\n",
    "df_model = df_model[df_model['ME.FMS.act.tPh']<8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features (X) from target (y)\n",
    "X = df_model.drop(['ME.FMS.act.tPh'], axis = 1)\n",
    "y = df_model['ME.FMS.act.tPh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high amount of data, a split into 10% test data and 90% train data is chosen. The random state is set to 42 to have comparable results for diffent models. To account for the imbalance in the distribution of passage types the stratify parameter is used for this feature. This results in approximately the same percentage of the different passage types in each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = X['passage_type'], test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy values for passage type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object types need to be transformed to dummy values. For this model this concerns the passage types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MLFlow connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLFlow is used to track and compare different models and model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.start_run(run_name='RandomForrest') \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all models in this project a MinMaxScaler is applied. For this model a random forrest is used. The hyperparameter are selected based on grid search and offer a reasonable balance between optimal results and overfitting. These settings are used in a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = make_pipeline(MinMaxScaler(), \n",
    "                        RandomForestRegressor(criterion= 'squared_error',\n",
    "                                            max_depth= 40, \n",
    "                                            max_features= 'auto',\n",
    "                                            max_leaf_nodes= 7000, \n",
    "                                            min_samples_split= 20,\n",
    "                                            n_estimators= 100, \n",
    "                                            random_state= 42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using train data\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions based on test and train data\n",
    "y_pred_test = forest.predict(X_test)\n",
    "y_pred_train = forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors and residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean squared error (RMSE) is used to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE train: ', mean_squared_error(y_train, y_pred_train, squared= False))\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared= False)\n",
    "print('RMSE test: ', mean_squared_error(y_test, y_pred_test, squared= False))\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting actual values against predicted shows that the points are close to the optimal diagonale. However, this plot and the yellowbrick residual plot show some dificulties the model has when predicting low target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(6, 6))\n",
    "plt.axline([1, 1], [2, 2],color='lightgrey')\n",
    "plt.scatter(y_train, y_pred_train, color ='#33424F')\n",
    "plt.scatter(y_test, y_pred_test, color = '#FF6600')\n",
    "plt.xticks(np.arange(0,7,1));\n",
    "plt.yticks(np.arange(0,7,1));\n",
    "plt.xlabel(\"ME.FMS.act.tPh actual\");\n",
    "plt.ylabel(\"ME.FMS.act.tPh predicted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ResidualsPlot(forest)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False prediction of target = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases the actual target value is zero, but the prediction are above zero. These are identified and further investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine actual and predicted target in one dataframe\n",
    "df_result_train = X_train.copy()\n",
    "df_result_train['predicted'] = y_pred_train\n",
    "df_result_train['actual'] = y_train\n",
    "\n",
    "# identify cases where the actual target = 0 and the prediction > 0.1\n",
    "df_target_zero_false = df_result_train[df_result_train['actual']==0]\n",
    "df_target_zero_false = df_target_zero_false[df_target_zero_false['predicted']>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_target_zero_false['V.SOG.act.kn'], \n",
    "    y=df_target_zero_false['predicted'],\n",
    "    mode='markers', marker=dict(color='#ff6600',size=5)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these predictions result from low speeds. An explation might be that the ship was pulled by a tugboat. Thus the model could be further improved by information about the operation of tugboats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following investigations focus on residuals >0.5 or <-0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate residuals\n",
    "df_result_train['residual'] = df_result_train['predicted'] - df_result_train['actual']\n",
    "# define high positive residuals\n",
    "df_residual_high_pos = df_result_train[df_result_train['residual']>0.5]\n",
    "# define high negative residuals\n",
    "df_residual_high_neg = df_result_train[df_result_train['residual']<-0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparisons with different features showed a clear pattern for longitude and latitude. There are almost no data point with high residuals on the Atlantic passages. This means the model predicts very well for the rather stable conditions on the Atlantic but would need additional data to better capture the routes to and from the ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12, 4), dpi=80)\n",
    "sns.scatterplot(data = df_residual_high_neg, \n",
    "                x = 'V.GPSLON.act.deg', \n",
    "                y = 'predicted',\n",
    "                linewidth=0\n",
    "                )\n",
    "sns.scatterplot(data = df_residual_high_pos, \n",
    "                x = 'V.GPSLON.act.deg', \n",
    "                y = 'predicted',\n",
    "                linewidth=0\n",
    "                );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12, 4), dpi=80)\n",
    "sns.scatterplot(data = df_residual_high_neg, \n",
    "                x = 'V.GPSLAT.act.deg', \n",
    "                y = 'predicted',\n",
    "                linewidth=0\n",
    "                )\n",
    "sns.scatterplot(data = df_residual_high_pos, \n",
    "                x = 'V.GPSLAT.act.deg', \n",
    "                y = 'predicted',\n",
    "                linewidth=0\n",
    "                );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different possibilities to identify important features. One way is to use the attribute impurity-based feature importances from scikit learn's RandomForestRegressor. The alternative is the permutation importance from scikit learn. Both identify the same top 6 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame({'features' : X_train.columns, 'importance' : forest['randomforestregressor'].feature_importances_})\n",
    "df_importance.sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    forest, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(\n",
    "    result.importances[sorted_idx].T, vert=False, labels=X_test.columns[sorted_idx]\n",
    ")\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seting parameters that should be logged on MLFlow\n",
    "# these parameters were used in feature engineering (inputing missing values)\n",
    "# or parameters of the model (fit_intercept for Linear Regression model)\n",
    "params = {\n",
    "      \"features drop\": 'According to model importance list',\n",
    "      \"criterion\": 'squared_error',\n",
    "      'max_features': 'auto',\n",
    "      \"random_state\": 42,\n",
    "      \"max_depth\": 40,\n",
    "      'max_leaf_nodes': 7000,\n",
    "      'min_samples_split': 20,\n",
    "      'n_estimators': 100,\n",
    "      \"csv used\": 'Featureselection03.csv',\n",
    "      \"NaN handling\": 'V.SLPOG.act.PRC and ME.SFCI.act.gPkWh filled with 0, rest dropped by row',\n",
    "      'Shape' : df.shape,\n",
    "      'Scaler' : 'MinMaxScaler'\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging params to mlflow\n",
    "mlflow.log_params(params)\n",
    "# setting tags\n",
    "mlflow.set_tag(\"running_from_jupyter\", \"True\")\n",
    "# logging metrics\n",
    "mlflow.log_metric(\"train-\" + \"RMSE\", rmse_train)\n",
    "mlflow.log_metric(\"test-\" + \"RMSE\", rmse_test)\n",
    "\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61adff6b165475bab44c4811cc98696ba601c22e85e1c32413c6c001d06d5e3a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
