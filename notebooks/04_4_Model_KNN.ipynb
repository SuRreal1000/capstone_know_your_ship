{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, the preparation of the data and the KNN model use are describe and shown.  \n",
    "Therefore the DataFrame from \"Featureengineering\" is loaded, together with the feature importance list for this particular model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# KNN Regression Model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Used in the Error Analysis\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "\n",
    "# required to safe the Model Parameters to MLFlow\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data file \"Featureengineering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .csv file\n",
    "df = pd.read_csv('../data/Featureselection03.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file \"Feature importance list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list with feature importance\n",
    "data_log = pd.read_csv('../data/Capstone_features_Features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A selection of the features is done by giving them a ModelImportance from 1 to 3, where 1 is important, 2 maybe important and 3 will be neglected.  \n",
    "Compared to the feature importance in teh \"Featureengineering\", this list keeps features which are important for this particular Machine Learning Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of important features (feature importance < 3)\n",
    "list_imp_feat = list(data_log[data_log['ModelImportance'] < 3]['VarName'])\n",
    "len(list_imp_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[list_imp_feat].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature list for the model is including also the target: Supply mass fuel rate of the Main Engine [t/h] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nan value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['V.SLPOG.act.PRC'].fillna(0,inplace=True)\n",
    "df_model['ME.SFCI.act.gPkWh'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nan values in the tow features are filled with 0, after investigating the data and coming to the conclusion, that the vessel is in the harbour and the Main Engine not running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional nan values are dropped, because the meaningful filling is not possible or to uncertain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,28))\n",
    "sns.heatmap(df_model.corr(), annot = True, cmap = 'RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix is checked again, to ensure no high correlations between features. The feature correlation has been checked in the \"Featureengineering\" already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target and Feature definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop(['ME.FMS.act.tPh'], axis = 1)\n",
    "y = df_model['ME.FMS.act.tPh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supply mass fuel rate as target is separated from the feature dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = X['passage_type'], test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Train split with random_state = 42 to have comparable dataset for the different models. Due to the size fo the dataset the test size is set rather small with 10%:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the passage type (Atalantic, Europe, South America) dummy features are created, to be able to feed the data to the model only as numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open MLFlow and definition of run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "#mlflow.set_tracking_uri(TRACKING_URI)\n",
    "#mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "#mlflow.start_run(run_name='KNN')\n",
    "#run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upload to MLFlow is enabled, to not upload any model results and because the setup is most probably not done for the machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipline with KNN Regressor and parameter definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = make_pipeline(MinMaxScaler(), KNeighborsRegressor(n_neighbors=4,\n",
    "                                                        metric='minkowski',\n",
    "                                                        p=2,\n",
    "                                                        n_jobs=-1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a model the k-nearest neighbors Regressor (KNN Regressor) is used, with a minMaxSacler.\n",
    "Using StandardScaler over MinMaxScaler gives not better RMSE values, hence the MinMAxScaler will be used for hte KNN Model.  \n",
    "\n",
    "The pipline is set up, with the  \n",
    "* model parameters: n_neighbors \n",
    "* Metric, p and n_jobs  \n",
    "\n",
    "The number of jobs is set to -1 to start all CPUs to fit and predict the model. This is important, because the KNN model is resource intensive and in this case took up to 30 minutes to predict, where the \"RandomForest\" model run only 2-3 minutes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model. For KNN this is very quick compared to other models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on the test dataset is taking some time, because the distances between the target and all datapoints in the dataset have to be calucalted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict y on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get residuals for the error analysis of regression models, the train datapoints have to be predicted as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model metric the root mean square error ( RMSE) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE train: ', mean_squared_error(y_train, y_pred_train, squared= False))\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared= False)\n",
    "print('RMSE test: ', mean_squared_error(y_test, y_pred, squared= False))\n",
    "rmse_test = mean_squared_error(y_test, y_pred, squared= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot \"Actuel\" vs. \"Predicted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(6, 6))\n",
    "plt.axline([1, 1], [2, 2],color='lightgrey')\n",
    "plt.scatter(y_train, y_pred_train, color ='#33424F')\n",
    "plt.scatter(y_test, y_pred, color = '#FF6600')\n",
    "plt.xlabel(\"ME.FMS.act.tPh actual\");\n",
    "plt.ylabel(\"ME.FMS.act.tPh predicted\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate residuals\n",
    "residuals_train = y_pred_train - y_train\n",
    "residuals_test = y_pred - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = y_pred_train, y = residuals_train)\n",
    "sns.scatterplot(x = y_pred, y = residuals_test)\n",
    "plt.axhline(y = 0, color = 'black')\n",
    "plt.xlabel(\"ME.FMS.act.tPh predicted\");\n",
    "plt.ylabel(\"Residuals\");\n",
    "plt.legend(labels=['', 'train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seting parameters that should be logged on MLFlow\n",
    "params = {\n",
    "    'csv used': 'Featureselection03.csv',\n",
    "    'features drop' : 'Accroding to model importance list',\n",
    "    'random_state' : 42,\n",
    "    'NaN handling' : 'dropped',  \n",
    "    'Shape' : df.shape,\n",
    "    'Scaler' : 'MinMaxScaler',\n",
    "    'K-Neighbors' : 4,\n",
    "    'metric' : 'minkowski',\n",
    "    'p' : 2\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down all parameters, which shall be uploaded to MLFlow. This can be different metrics for different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging params to mlflow\n",
    "#mlflow.log_params(params)\n",
    "\n",
    "#setting tags\n",
    "#mlflow.set_tag(\"running_from_jupyter\", \"True\")\n",
    "\n",
    "#logging metrics\n",
    "#mlflow.log_metric(\"train-\" + \"RMSE\", rmse_train)\n",
    "#mlflow.log_metric(\"test-\" + \"RMSE\", rmse_test)\n",
    "\n",
    "# logging the model to mlflow will not work without a AWS Connection setup.. too complex for now\n",
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the upload to MLFlow is enabled to not accidentely try to upload new model runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summery of KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN model is taking to much time to predict, compared to other ML models. In this case, with the high frequency data, the amount of data is most probably too high for an efficient KNN model.  \n",
    "Compared to other models, the RMSE is not as low as from other models. Hence, with a long runtime and medium good RMSE values the KNN is not the prefered model to continue with."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61adff6b165475bab44c4811cc98696ba601c22e85e1c32413c6c001d06d5e3a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
