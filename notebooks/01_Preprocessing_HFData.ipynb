{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Guayaquil Express - Combine Database Files\n",
    "<sub><sup> Markus Böswetter - 11th November 2021</sup></sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes raw information and provides at the end a `single CSV file`. This file contains 5 month of vessel-sensor-data, July 2021 until end of October 2021, including a timestamp in minute intervals and 110 other features.\n",
    "\n",
    "The original raw data was provided within single db-files (.s3db format), containing db-tables where two have been used in this notebook:\n",
    "* DataLogEntry: containing sensor data;\n",
    "* DataLog: containing high level information on the different features.\n",
    "\n",
    "For some features, the sensor data is available in 5 seconds and 10 seconds frequency. However for the majority the data is only available in 1 minute steps. In addition, for some timestamps multiple measurements are logged. In order to reduce sensor data to one measurement per minute, multiple measurements per minute (e.g. 5sec, 10sec, or multiple measurements per minute) the first value was taken.\n",
    "\n",
    "The dataset further contained column/feature, called EntryState. For EntryState = 0 all values were observed to be 0. It is assumed that for those Values are not available and were set to NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "  \n",
    "1) Copy 'GUAX_Bluetracker' Files into repos data folder.\n",
    "\n",
    "2) If required, adjust folder/dbfiles information in `File setting` section below\n",
    "\n",
    "3) Run Main Code, CSVs will be saved to repos data folder\n",
    "    * STAGE_Bluetracker.csv: Combined db-files to one csv;\n",
    "    * FINAL_Bluetracker.csv: Adjusted Headings and Columns with only NaN values removed > 110 features remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only few Libraries required for this notebook. \n",
    "* sqlite3 for reading the db-files using SQL;\n",
    "* os to read filenames in folder;\n",
    "* `magic happens all in pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those tree functions are used for:\n",
    "* Combining the raw db-files (beginning of this notebook);\n",
    "* Header matching (see end of this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get List with File Names (Full Path) / Loop through given dictionary\n",
    "def _fGetFullPathFileList(directory_in_str, filetype=\".s3db\"):\n",
    "    '''\n",
    "    This function returns a list. The list includes the full path of files in a given directory that match >filetype< \n",
    "    '''\n",
    "    directory = os.fsencode(directory_in_str)\n",
    "    files = []\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(filetype): # or filename.endswith(\".py\"): \n",
    "            #print(f'{directory_in_str}/{filename}')\n",
    "            files.append(f'{directory_in_str}/{filename}')\n",
    "            #print(directory)\n",
    "            #print(os.path.join(directory, filename))\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    return files\n",
    "#print(_fGetFullPathFileList(FILEDIR, '.s3db')[0:5])\n",
    "\n",
    "# Retruns Db-Table as Dataframe\n",
    "def _fGetDBTableDataframe(full_dbpath_as_str, tablename_as_str):\n",
    "    '''\n",
    "    Returns a Dataframe with all Data from a given database and tablename. Requires 'import sqlite3' library\n",
    "    '''\n",
    "    try:\n",
    "        cnx = sqlite3.connect(full_dbpath_as_str)\n",
    "        cur = cnx.cursor()\n",
    "        #print(\"Database created and Successfully Connected to SQLite\")\n",
    "\n",
    "        # Read table to dataframe\n",
    "        path = f'SELECT * FROM {tablename_as_str}'\n",
    "        df = pd.read_sql_query(path, cnx)\n",
    "\n",
    "        cur.close()\n",
    "\n",
    "    except sqlite3.Error as error:\n",
    "        print(f\"{full_dbpath_as_str} >> Error while connecting to sqlite:\", error)\n",
    "    finally:\n",
    "        if cnx:\n",
    "            cnx.close()\n",
    "\n",
    "            #print(\"The SQLite connection is closed\")\n",
    "            return df.copy()\n",
    "\n",
    "# Combines DB-Tables to one DataFrame. It takes a list of DBfilenames and the tablename as input\n",
    "def _fCombinedTableDataframe(list_db_paths, table_name='Log_10s', status=False):\n",
    "    '''\n",
    "    Write single db tables into one dataframe. Calls _fGetDBTableDataframe\n",
    "    '''\n",
    "    print('-'*50)\n",
    "    print(f'Combining Tables: {table_name}')\n",
    "    i = 0\n",
    "    frames = []\n",
    "    for s3db in list_db_paths:\n",
    "        df = _fGetDBTableDataframe(s3db, table_name)\n",
    "        frames = pd.concat([pd.DataFrame(frames), df])\n",
    "        del df\n",
    "        # Just some stupid status bar :P\n",
    "        if status:\n",
    "            i += 1\n",
    "            l = len(list_db_paths)\n",
    "            if i % 6 == 0 or i == l:\n",
    "                print('|', '#' * i, ' ' * (l - i), '|', frames.shape)\n",
    "\n",
    "    print(f'Finished combining tables \"{table_name}\" | Shape: {frames.shape} ')\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `File Settings`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the Folder path where all our .s3db Files are. Further we define the Table name where the measurements are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are the db-files stored?\n",
    "FILEDIR = '../data/GUAX-Bluetracker'\n",
    "\n",
    "# Whats the type of the DB file?\n",
    "DBTYPE = '.s3db'\n",
    "\n",
    "# What is the relevant Tablename?\n",
    "TABLE_NAME = 'DataLogEntry'\n",
    "\n",
    "# Where would you like to save CSV files?\n",
    "CSVFOLDER = '../data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Get Raw data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the code to combine all our single Tables into one dataframe/csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(FILEDIR)\n",
    "    # Run the code to combine all DB Tables / Runtime for 6 month Bluetracker Data = 30ish minutes\n",
    "    df = _fCombinedTableDataframe(_fGetFullPathFileList(FILEDIR, DBTYPE), TABLE_NAME, True)\n",
    "\n",
    "    # Save the data to predefined folder\n",
    "    df.to_csv(f'{CSVFOLDER}/STAGE_Bluetracker.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative, if you already run the combine code above you can simply load the csv-file. This is way faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (39440874, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{CSVFOLDER}/STAGE_Bluetracker.csv')    # 30-40 seconds runtime\n",
    "print(f'Dataframe shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape after dropping EntryState==0: (38422797, 4)\n"
     ]
    }
   ],
   "source": [
    "# Delete EntryState = 0 Values\n",
    "df = df[df.EntryState==2].copy()\n",
    "df.drop('EntryState', inplace=True, axis=1)\n",
    "print(f'Dataframe shape after dropping EntryState==0: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of seconds for Entry Date\n",
    "df['EntryDate'] = df.EntryDate.apply(lambda row: str(row)[0:16])\n",
    "\n",
    "# Change EntryDate to datetime type\n",
    "df['EntryDate'] = pd.to_datetime(df['EntryDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty Dataframe\n",
    "df_dates = pd.DataFrame()\n",
    "\n",
    "# Create Date Values and rename Column\n",
    "df_dates['EntryDate'] = pd.date_range(start=df['EntryDate'].min(), end=df['EntryDate'].max(), freq='T')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape after dropping duplicates: (23380630, 4)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(subset=['EntryDate', 'DataLogID'], keep='first', inplace=True)\n",
    "print(f'Dataframe shape after dropping duplicates: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='DataLogEntryID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_logid = list(df.DataLogID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape after dropping duplicates: (220321, 123)\n"
     ]
    }
   ],
   "source": [
    "# Write DataLogIDs to own column\n",
    "for LOGID in list_logid:\n",
    "    df_dates = pd.merge(df_dates, df[df.DataLogID == LOGID].drop(columns='DataLogID'), how='left', on='EntryDate')\n",
    "    df_dates.rename(columns={\"EntryValue\": LOGID}, inplace=True)\n",
    "df = df_dates.copy()\n",
    "del df_dates\n",
    "print(f'Dataframe shape after dropping duplicates: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryDate</th>\n",
       "      <th>11014</th>\n",
       "      <th>11011</th>\n",
       "      <th>11015</th>\n",
       "      <th>11020</th>\n",
       "      <th>11017</th>\n",
       "      <th>11021</th>\n",
       "      <th>14003</th>\n",
       "      <th>11012</th>\n",
       "      <th>11016</th>\n",
       "      <th>...</th>\n",
       "      <th>12070</th>\n",
       "      <th>12061</th>\n",
       "      <th>12062</th>\n",
       "      <th>14006</th>\n",
       "      <th>13004</th>\n",
       "      <th>14005</th>\n",
       "      <th>13002</th>\n",
       "      <th>13000</th>\n",
       "      <th>13003</th>\n",
       "      <th>13001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-31 00:00:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-31 00:01:00</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>86402.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>192.031204</td>\n",
       "      <td>293.132843</td>\n",
       "      <td>290.477203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-31 00:02:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>86402.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>193.393600</td>\n",
       "      <td>291.190186</td>\n",
       "      <td>289.918213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-31 00:03:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>86402.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>194.051834</td>\n",
       "      <td>290.139618</td>\n",
       "      <td>291.215454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-31 00:04:00</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>86402.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>195.484314</td>\n",
       "      <td>288.614624</td>\n",
       "      <td>285.923615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            EntryDate  11014  11011  11015  11020  11017  11021         14003  \\\n",
       "0 2021-05-31 00:00:00   65.0    0.0 -0.004   28.0    0.0 -0.002  1.622416e+09   \n",
       "1 2021-05-31 00:01:00   58.0    0.0 -0.003   25.0    0.0 -0.002  1.622416e+09   \n",
       "2 2021-05-31 00:02:00   63.0    0.0  0.007   27.0    0.0  0.000  1.622416e+09   \n",
       "3 2021-05-31 00:03:00   63.0    0.0  0.008   27.0    0.0 -0.001  1.622416e+09   \n",
       "4 2021-05-31 00:04:00   64.0    0.0  0.000   27.0    0.0 -0.001  1.622416e+09   \n",
       "\n",
       "     11012  11016  ...       12070       12061       12062  14006  13004  \\\n",
       "0      NaN    NaN  ...         NaN         NaN         NaN    NaN    NaN   \n",
       "1  86402.0  1.343  ...  192.031204  293.132843  290.477203    NaN    NaN   \n",
       "2  86402.0  1.343  ...  193.393600  291.190186  289.918213    NaN    NaN   \n",
       "3  86402.0  1.343  ...  194.051834  290.139618  291.215454    NaN    NaN   \n",
       "4  86402.0  1.343  ...  195.484314  288.614624  285.923615    NaN    NaN   \n",
       "\n",
       "   14005  13002  13000  13003  13001  \n",
       "0    NaN    NaN    NaN    NaN    NaN  \n",
       "1    NaN    NaN    NaN    NaN    NaN  \n",
       "2    NaN    NaN    NaN    NaN    NaN  \n",
       "3    NaN    NaN    NaN    NaN    NaN  \n",
       "4    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Column /Feature Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information about the Features/Sensors/Columns are stored in the db-files in a Table called `DataLog`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/GUAX-Bluetracker/iMCALog 20210623_0000.s3db\n"
     ]
    }
   ],
   "source": [
    "# Get some db file path + name\n",
    "files = _fGetFullPathFileList(FILEDIR, DBTYPE)\n",
    "print(files[0])\n",
    "\n",
    "# Read to dataframe\n",
    "df_heading = _fGetDBTableDataframe(files[0], 'DataLog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataLogID</th>\n",
       "      <th>LogName</th>\n",
       "      <th>VarName</th>\n",
       "      <th>FullPath</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Permission</th>\n",
       "      <th>ShortName</th>\n",
       "      <th>LongName</th>\n",
       "      <th>Units</th>\n",
       "      <th>Format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11011</td>\n",
       "      <td>log_LM1_plc_skewtime.act.s</td>\n",
       "      <td>LM1.plc_skewtime.act.s</td>\n",
       "      <td>DPS_Local:LM1:LM1.plc_skewtime.act.s</td>\n",
       "      <td>Int_Unscaled</td>\n",
       "      <td>Read</td>\n",
       "      <td>LM1 plc_skewtime</td>\n",
       "      <td>plc_skewtime</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11012</td>\n",
       "      <td>log_LM1_plc_skewtime.max.s</td>\n",
       "      <td>LM1.plc_skewtime.max.s</td>\n",
       "      <td>DPS_Local:LM1:LM1.plc_skewtime.max.s</td>\n",
       "      <td>Int_Unscaled</td>\n",
       "      <td>Read</td>\n",
       "      <td>LM1 plc_skewtime</td>\n",
       "      <td>plc_skewtime_max</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11013</td>\n",
       "      <td>log_LM1_plc_uptime.act.s</td>\n",
       "      <td>LM1.plc_uptime.act.s</td>\n",
       "      <td>DPS_Local:LM1:LM1.plc_uptime.act.s</td>\n",
       "      <td>Int_Unscaled</td>\n",
       "      <td>Read</td>\n",
       "      <td>LM1 plc_uptime</td>\n",
       "      <td>plc_uptime.act.s</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11014</td>\n",
       "      <td>log_LM1_plc_cpuload.avg_5s.PRC</td>\n",
       "      <td>LM1.plc_cpuload.avg_5s.PRC</td>\n",
       "      <td>DPS_Local:LM1:LM1.plc_cpuload.avg_5s.PRC</td>\n",
       "      <td>Int_Unscaled</td>\n",
       "      <td>Read</td>\n",
       "      <td>LM1 PLC avg. CPU Load</td>\n",
       "      <td>LM1: PLC avg. CPU Load</td>\n",
       "      <td>%</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11015</td>\n",
       "      <td>log_LM1_plc_timeBalance.act.s</td>\n",
       "      <td>LM1.plc_timeBalance.act.s</td>\n",
       "      <td>DPS_Local:LM1:LM1.plc_timeBalance.act.s</td>\n",
       "      <td>Float_Unscaled</td>\n",
       "      <td>Read</td>\n",
       "      <td>LM1 plc_timeBalance.act.s</td>\n",
       "      <td>plc_timeBalance.act.s</td>\n",
       "      <td>s</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DataLogID                         LogName                     VarName  \\\n",
       "0      11011      log_LM1_plc_skewtime.act.s      LM1.plc_skewtime.act.s   \n",
       "1      11012      log_LM1_plc_skewtime.max.s      LM1.plc_skewtime.max.s   \n",
       "2      11013        log_LM1_plc_uptime.act.s        LM1.plc_uptime.act.s   \n",
       "3      11014  log_LM1_plc_cpuload.avg_5s.PRC  LM1.plc_cpuload.avg_5s.PRC   \n",
       "4      11015   log_LM1_plc_timeBalance.act.s   LM1.plc_timeBalance.act.s   \n",
       "\n",
       "                                   FullPath        DataType Permission  \\\n",
       "0      DPS_Local:LM1:LM1.plc_skewtime.act.s    Int_Unscaled       Read   \n",
       "1      DPS_Local:LM1:LM1.plc_skewtime.max.s    Int_Unscaled       Read   \n",
       "2        DPS_Local:LM1:LM1.plc_uptime.act.s    Int_Unscaled       Read   \n",
       "3  DPS_Local:LM1:LM1.plc_cpuload.avg_5s.PRC    Int_Unscaled       Read   \n",
       "4   DPS_Local:LM1:LM1.plc_timeBalance.act.s  Float_Unscaled       Read   \n",
       "\n",
       "                   ShortName                LongName Units Format  \n",
       "0           LM1 plc_skewtime            plc_skewtime     s      0  \n",
       "1           LM1 plc_skewtime        plc_skewtime_max     s      0  \n",
       "2             LM1 plc_uptime        plc_uptime.act.s     s      0  \n",
       "3      LM1 PLC avg. CPU Load  LM1: PLC avg. CPU Load     %      0  \n",
       "4  LM1 plc_timeBalance.act.s   plc_timeBalance.act.s     s  0.000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heading.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate VarNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, som VarNames appearing multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V.STW.act.kn           2\n",
       "AE.SFC.act.gPkWh       2\n",
       "ME.LOD.act.PRC         2\n",
       "ME.SFC.act.gPkWh       2\n",
       "V.SLPTW.act.PRC        2\n",
       "VME.SFCTW.act.kgPNM    1\n",
       "Name: VarName, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heading.VarName.value_counts().head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_varname = {13002: 'ME.LOD.act.PRC.trend', \\\n",
    "    13003: 'ME.SFC.act.gPkWh.trend', \\\n",
    "        13004: 'AE.SFC.act.gPkWh.trend', \\\n",
    "            13006: 'V.SLPTW.act.PRC.trend', \\\n",
    "                14005: 'V.STW.act.kn.trend'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataLogID</th>\n",
       "      <th>LogName</th>\n",
       "      <th>VarName</th>\n",
       "      <th>FullPath</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Permission</th>\n",
       "      <th>ShortName</th>\n",
       "      <th>LongName</th>\n",
       "      <th>Units</th>\n",
       "      <th>Format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12002</td>\n",
       "      <td>log_ME.LOD.act.PRC</td>\n",
       "      <td>ME.LOD.act.PRC</td>\n",
       "      <td>DPS_Local:LM1:ME.LOD.act.PRC</td>\n",
       "      <td>Float_Unscaled</td>\n",
       "      <td>Read</td>\n",
       "      <td>ME Load</td>\n",
       "      <td>ME Load</td>\n",
       "      <td>%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>13002</td>\n",
       "      <td>trendlog_ME.LOD.act.PRC</td>\n",
       "      <td>ME.LOD.act.PRC</td>\n",
       "      <td>DPS_Local:LM1:ME.LOD.act.PRC</td>\n",
       "      <td>Float_Unscaled</td>\n",
       "      <td>Read</td>\n",
       "      <td>ME Load</td>\n",
       "      <td>ME Load</td>\n",
       "      <td>%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DataLogID                  LogName         VarName  \\\n",
       "13       12002       log_ME.LOD.act.PRC  ME.LOD.act.PRC   \n",
       "109      13002  trendlog_ME.LOD.act.PRC  ME.LOD.act.PRC   \n",
       "\n",
       "                         FullPath        DataType Permission ShortName  \\\n",
       "13   DPS_Local:LM1:ME.LOD.act.PRC  Float_Unscaled       Read   ME Load   \n",
       "109  DPS_Local:LM1:ME.LOD.act.PRC  Float_Unscaled       Read   ME Load   \n",
       "\n",
       "    LongName Units Format  \n",
       "13   ME Load     %    0.0  \n",
       "109  ME Load     %    0.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heading[df_heading.VarName=='ME.LOD.act.PRC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will match now the DataLogID with the VarName and replace the column/feature names by `VarName`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "for LOGID in list_logid:\n",
    "    if LOGID in dic_varname:\n",
    "        VARNAME = dic_varname[LOGID]\n",
    "    else:\n",
    "        VARNAME = df_heading[df_heading.DataLogID == LOGID].VarName.unique()[0]\n",
    "    df.rename(columns={LOGID: VARNAME}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryDate</th>\n",
       "      <th>LM1.plc_cpuload.avg_5s.PRC</th>\n",
       "      <th>LM1.plc_skewtime.act.s</th>\n",
       "      <th>LM1.plc_timeBalance.act.s</th>\n",
       "      <th>LM2.plc_cpuload.avg_5s.PRC</th>\n",
       "      <th>LM2.plc_skewtime.act.s</th>\n",
       "      <th>LM2.plc_timeBalance.act.s</th>\n",
       "      <th>TI.LOC.act.ts</th>\n",
       "      <th>LM1.plc_skewtime.max.s</th>\n",
       "      <th>LM1.plc_timeBalance.max.s</th>\n",
       "      <th>...</th>\n",
       "      <th>VME.SFCTW.act.kgPNM</th>\n",
       "      <th>V.SFCOG.act.kgPNM</th>\n",
       "      <th>V.SFCTW.act.kgPNM</th>\n",
       "      <th>V.SLPTW.act.PRC</th>\n",
       "      <th>AE.SFC.act.gPkWh.trend</th>\n",
       "      <th>V.STW.act.kn.trend</th>\n",
       "      <th>ME.LOD.act.PRC.trend</th>\n",
       "      <th>ME.POW.act.MW</th>\n",
       "      <th>ME.SFC.act.gPkWh.trend</th>\n",
       "      <th>ME.SPD.act.rpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-31 00:00:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-31 00:01:00</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>86402.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>192.031204</td>\n",
       "      <td>293.132843</td>\n",
       "      <td>290.477203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-31 00:02:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>86402.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>193.393600</td>\n",
       "      <td>291.190186</td>\n",
       "      <td>289.918213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-31 00:03:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>86402.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>194.051834</td>\n",
       "      <td>290.139618</td>\n",
       "      <td>291.215454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-31 00:04:00</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>1.622416e+09</td>\n",
       "      <td>86402.0</td>\n",
       "      <td>1.343</td>\n",
       "      <td>...</td>\n",
       "      <td>195.484314</td>\n",
       "      <td>288.614624</td>\n",
       "      <td>285.923615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            EntryDate  LM1.plc_cpuload.avg_5s.PRC  LM1.plc_skewtime.act.s  \\\n",
       "0 2021-05-31 00:00:00                        65.0                     0.0   \n",
       "1 2021-05-31 00:01:00                        58.0                     0.0   \n",
       "2 2021-05-31 00:02:00                        63.0                     0.0   \n",
       "3 2021-05-31 00:03:00                        63.0                     0.0   \n",
       "4 2021-05-31 00:04:00                        64.0                     0.0   \n",
       "\n",
       "   LM1.plc_timeBalance.act.s  LM2.plc_cpuload.avg_5s.PRC  \\\n",
       "0                     -0.004                        28.0   \n",
       "1                     -0.003                        25.0   \n",
       "2                      0.007                        27.0   \n",
       "3                      0.008                        27.0   \n",
       "4                      0.000                        27.0   \n",
       "\n",
       "   LM2.plc_skewtime.act.s  LM2.plc_timeBalance.act.s  TI.LOC.act.ts  \\\n",
       "0                     0.0                     -0.002   1.622416e+09   \n",
       "1                     0.0                     -0.002   1.622416e+09   \n",
       "2                     0.0                      0.000   1.622416e+09   \n",
       "3                     0.0                     -0.001   1.622416e+09   \n",
       "4                     0.0                     -0.001   1.622416e+09   \n",
       "\n",
       "   LM1.plc_skewtime.max.s  LM1.plc_timeBalance.max.s  ...  \\\n",
       "0                     NaN                        NaN  ...   \n",
       "1                 86402.0                      1.343  ...   \n",
       "2                 86402.0                      1.343  ...   \n",
       "3                 86402.0                      1.343  ...   \n",
       "4                 86402.0                      1.343  ...   \n",
       "\n",
       "   VME.SFCTW.act.kgPNM  V.SFCOG.act.kgPNM  V.SFCTW.act.kgPNM  V.SLPTW.act.PRC  \\\n",
       "0                  NaN                NaN                NaN              NaN   \n",
       "1           192.031204         293.132843         290.477203              NaN   \n",
       "2           193.393600         291.190186         289.918213              NaN   \n",
       "3           194.051834         290.139618         291.215454              NaN   \n",
       "4           195.484314         288.614624         285.923615              NaN   \n",
       "\n",
       "   AE.SFC.act.gPkWh.trend  V.STW.act.kn.trend  ME.LOD.act.PRC.trend  \\\n",
       "0                     NaN                 NaN                   NaN   \n",
       "1                     NaN                 NaN                   NaN   \n",
       "2                     NaN                 NaN                   NaN   \n",
       "3                     NaN                 NaN                   NaN   \n",
       "4                     NaN                 NaN                   NaN   \n",
       "\n",
       "   ME.POW.act.MW  ME.SFC.act.gPkWh.trend  ME.SPD.act.rpm  \n",
       "0            NaN                     NaN             NaN  \n",
       "1            NaN                     NaN             NaN  \n",
       "2            NaN                     NaN             NaN  \n",
       "3            NaN                     NaN             NaN  \n",
       "4            NaN                     NaN             NaN  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220321, 123)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready and can save our DataFrame to our FINAL_Bluetracker.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('EntryDate', inplace=True)\n",
    "df.to_csv(f'{CSVFOLDER}/FINAL_Bluetracker_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntryDate                          0\n",
       "LM1.plc_cpuload.avg_5s.PRC      8642\n",
       "LM1.plc_skewtime.act.s          8642\n",
       "LM1.plc_timeBalance.act.s       8642\n",
       "LM2.plc_cpuload.avg_5s.PRC      8642\n",
       "                               ...  \n",
       "V.STW.act.kn.trend            220319\n",
       "ME.LOD.act.PRC.trend          220319\n",
       "ME.POW.act.MW                 220319\n",
       "ME.SFC.act.gPkWh.trend        220319\n",
       "ME.SPD.act.rpm                220319\n",
       "Length: 123, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad8f7a3d93ea9b275449e95c0ce6ee25301282232d0b608b79db5bcbac100c75"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
